{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12787642,"sourceType":"datasetVersion","datasetId":8084743},{"sourceId":12787652,"sourceType":"datasetVersion","datasetId":8084750}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# ----------------------------\n# Basic 3x3 Convolution\n# ----------------------------\ndef conv3x3(in_planes, out_planes, stride=1):\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n\n# ----------------------------\n# Basic Residual Block\n# ----------------------------\nclass BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, in_planes, planes, stride=1, downsample=None, is_last=False):\n        super().__init__()\n        self.is_last = is_last\n        self.conv1 = conv3x3(in_planes, planes, stride)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(planes, planes)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.downsample = downsample\n\n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n        out += residual\n        preact = out\n        out = F.relu(out)\n\n        if self.is_last:\n            return out, preact\n        else:\n            return out\n\n# ----------------------------\n# ResNet CIFAR Modular\n# ----------------------------\nclass ResNet(nn.Module):\n    def __init__(self, depth, num_filters=[16,16,32,64], block_name='basicblock', num_classes=100):\n        super().__init__()\n        assert block_name.lower() == 'basicblock', \"Currently only BasicBlock supported\"\n        assert (depth - 2) % 6 == 0, \"Depth must be 6n+2 for BasicBlock\"\n        n = (depth - 2) // 6\n\n        self.in_planes = num_filters[0]\n        self.conv1 = conv3x3(3, num_filters[0])\n        self.bn1 = nn.BatchNorm2d(num_filters[0])\n        self.relu = nn.ReLU(inplace=True)\n\n        # Residual layers\n        self.layer1 = self._make_layer(BasicBlock, num_filters[1], n)\n        self.layer2 = self._make_layer(BasicBlock, num_filters[2], n, stride=2)\n        self.layer3 = self._make_layer(BasicBlock, num_filters[3], n, stride=2)\n\n        self.avgpool = nn.AvgPool2d(8)\n        self.fc = nn.Linear(num_filters[3]*BasicBlock.expansion, num_classes)\n\n        # weight init\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n\n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.in_planes != planes*block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.in_planes, planes*block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes*block.expansion)\n            )\n\n        layers = [block(self.in_planes, planes, stride, downsample, is_last=(blocks==1))]\n        self.in_planes = planes*block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.in_planes, planes, is_last=(i==blocks-1)))\n        return nn.Sequential(*layers)\n\n    def forward(self, x, is_feat=False, preact=False):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        f0 = x\n\n        x, f1_pre = self.layer1(x)\n        f1 = x\n        x, f2_pre = self.layer2(x)\n        f2 = x\n        x, f3_pre = self.layer3(x)\n        f3 = x\n\n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        f4 = x\n        x = self.fc(x)\n\n        if is_feat:\n            return ([f0,f1,f2,f3,f4], x) if not preact else ([f0,f1_pre,f2_pre,f3_pre,f4], x)\n        else:\n            return x\n\n# ----------------------------\n# Architecture builders\n# ----------------------------\ndef resnet20(num_classes=100): return ResNet(20, num_classes=num_classes)\ndef resnet32(num_classes=100):\n    \"\"\"ResNet32 matching the standard CIFAR ResNet paper structure.\"\"\"\n    # Use num_filters=[32, 32, 64, 128] to match the checkpoint you want to load\n    return ResNet(depth=32, num_filters=[32, 64, 128, 256], block_name='basicblock', num_classes=num_classes)\n\ndef resnet56(num_classes=100): return ResNet(56, num_classes=num_classes)\ndef resnet110(num_classes=100): return ResNet(110, num_classes=num_classes)\ndef resnet32_basic(num_classes=100): return ResNet(32, num_classes=num_classes)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:18:49.396554Z","iopub.execute_input":"2025-08-19T10:18:49.397375Z","iopub.status.idle":"2025-08-19T10:18:50.976005Z","shell.execute_reply.started":"2025-08-19T10:18:49.397336Z","shell.execute_reply":"2025-08-19T10:18:50.975347Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\n# ---------------------------\n# Device\n# ---------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ---------------------------\n# CIFAR-100 test dataset\n# ---------------------------\nmean = (0.5071, 0.4867, 0.4408)\nstd  = (0.2675, 0.2565, 0.2761)\n\ntest_tf = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\ntest_ds = datasets.CIFAR100(\"./data\", train=False, transform=test_tf, download=True)\ntest_loader = DataLoader(test_ds, batch_size=128, shuffle=False, num_workers=2, pin_memory=True)\n\n# ---------------------------\n# Model constructors\n# ---------------------------\nmodel_dict = {\n    # \"ResNet20\": resnet20,\n    # \"ResNet32\": resnet32(), # this is the resnet-32x4\n    \"ResNet56\": resnet56(),\n    \"ResNet110\": resnet110()\n}\n\n# Path mapping for pretrained weights (adjust paths if needed)\nweights_dict = {\n    # \"ResNet20\": \"/path/to/resnet20.pth\",\n    # \"ResNet32\": \"/kaggle/input/resnet32/pytorch/default/1/ckpt_epoch_240.pth\",\n    \"ResNet56\":  \"/kaggle/input/resnet-56/ckpt_epoch_240.pth\",\n    \"ResNet110\": \"/kaggle/input/resnet-110/ckpt_epoch_240.pth\"\n}\n\n# ---------------------------\n# Evaluation loop\n# ---------------------------\nfor name, constructor in model_dict.items():\n    print(f\"Evaluating {name}...\")\n    model = constructor.to(device)\n    \n    # Load pretrained weights if available\n    weight_path = weights_dict.get(name)\n    if weight_path:\n        checkpoint = torch.load(weight_path, map_location=device,weights_only=False)\n        if 'model' in checkpoint:\n            state_dict = checkpoint['model']\n        else:\n            state_dict = checkpoint\n        model.load_state_dict(state_dict)\n    \n    model.eval()\n    correct = total = 0\n    with torch.no_grad():\n        for imgs, labels in test_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            logits = model(imgs)\n            preds = logits.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n    test_acc = 100 * correct / total\n    print(f\"ðŸŽ¯ {name} Test Accuracy on CIFAR-100: {test_acc:.2f}%\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:18:50.977212Z","iopub.execute_input":"2025-08-19T10:18:50.977619Z","iopub.status.idle":"2025-08-19T10:18:59.738467Z","shell.execute_reply.started":"2025-08-19T10:18:50.977596Z","shell.execute_reply":"2025-08-19T10:18:59.737614Z"}},"outputs":[{"name":"stdout","text":"Evaluating ResNet56...\nðŸŽ¯ ResNet56 Test Accuracy on CIFAR-100: 72.41%\n\nEvaluating ResNet110...\nðŸŽ¯ ResNet110 Test Accuracy on CIFAR-100: 74.31%\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Training the student models BASIC Resnet 20 / 32","metadata":{}},{"cell_type":"markdown","source":"import os\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy, RandomErasing\nfrom tqdm.auto import tqdm\n#from torchvision.models import resnet18, resnet34\n\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nuse_dp = torch.cuda.device_count() > 1\ntorch.manual_seed(42)\nnp.random.seed(42)\n\nmean = (0.5071, 0.4867, 0.4408)  # CIFAR-100 mean\nstd  = (0.2675, 0.2565, 0.2761)  # CIFAR-100 std\n\nbatch_size = 64\n\n# Precompute DataLoaders for each resolution\nstages = [(r) for r in [(32, 240)]]\ndataloader_dict = {}\n\n'''\nCopied from the paper as it is.\n\nthey are not using any validation sets. Training it on the entire train set!\n    train_transform = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=mean, std=stdv),\n    ])\n    test_transform = transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize(mean=mean, std=stdv),\n    ])\n    \n    '''\n\nfor resolution, _ in stages:\n    train_tf = transforms.Compose([\n        transforms.RandomCrop(resolution,padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std),\n    ])\n    \n    train_set = datasets.CIFAR100('./data', train=True, download=False, transform=train_tf)\n    \n    train_loader = DataLoader(train_set, batch_size=batch_size,\n                              shuffle=True, num_workers=0, pin_memory=True)\n    dataloader_dict[resolution] = {\n        'train': train_loader\n    }\n\n# Test loader (fixed resolution)\ntest_tf = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std),\n])\n\ntest_ds = datasets.CIFAR100('./data', train=False, transform=test_tf)\ntest_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)\n\n\n# learning_rate is divided by 10 \n\n# ---------------------------\n# Test loop\n# ---------------------------\n\ndef test(Test_model):\n    \n    Test_model.eval()\n    correct_val = total_val = 0\n    \n    with torch.no_grad():\n        for imgs, labels in test_loader:\n            imgs, labels = imgs.to(device), labels.to(device)\n            logits = Test_model(imgs)\n            preds = logits.argmax(1)\n            correct_val += (preds == labels).sum().item()\n            total_val += labels.size(0)\n    test_acc = 100 * correct_val / total_val\n\n    # print(f\"Test Acc = {val_acc:.2f}%\")\n    return test_acc\n\n# ---------------------------\n# Training loop\n# ---------------------------\n\ndef train(model, model_type):\n    \n    # Loss + optimizer\n    lr = 0.05 # as per the paper\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n\n    # Step LR schedule: decay at 150, 180, 210 epochs\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 180, 210], gamma=0.1)\n\n    best_val_acc = 0.0\n    num_epochs = 240\n    \n    for res, epochs in stages:\n        \n        print(f\"\\n=== Training at resolution {res}px ===\")\n        tr_loader = dataloader_dict[res]['train']\n        \n        for e in range(1, epochs+1):\n            \n            model.train()\n            total_loss = 0\n            correct = total = 0\n        \n            for imgs, labels in tqdm(tr_loader, desc=f\"Epoch {e}/{num_epochs}\"):\n                \n                imgs, labels = imgs.to(device), labels.to(device)\n                optimizer.zero_grad()\n                logits = model(imgs)\n                loss = criterion(logits, labels)\n                loss.backward()\n                optimizer.step()\n        \n                total_loss += loss.item()\n                preds = logits.argmax(1)\n                correct += (preds == labels).sum().item()\n                total += labels.size(0)\n        \n            train_acc = 100 * correct / total\n            scheduler.step()\n\n            test_acc = test(model)\n            \n            print(f\"Epoch {e}: Train Acc = {train_acc:.2f}% Test Accuracy = {test_acc:.2f}%\") \n            \n            # Save best model\n            if test_acc > best_val_acc:\n                best_val_acc = test_acc\n                torch.save(model.state_dict(), f\"resnet{model_type}_student.pth\")\n                print(f\"â†’ Saved best model at epoch {e} with Test Acc = {train_acc:.2f}%\")\n    print(\"âœ… Training completed!\")","metadata":{"execution":{"iopub.status.busy":"2025-08-17T08:17:09.532251Z","iopub.execute_input":"2025-08-17T08:17:09.533063Z","iopub.status.idle":"2025-08-17T08:17:10.690719Z","shell.execute_reply.started":"2025-08-17T08:17:09.533033Z","shell.execute_reply":"2025-08-17T08:17:10.690125Z"}}},{"cell_type":"markdown","source":"# KD Training Vanilla\n","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Subset\nfrom torchvision import datasets, transforms\nfrom torchvision.transforms import AutoAugment, AutoAugmentPolicy, RandomErasing\nfrom tqdm.auto import tqdm\n#from torchvision.models import resnet18, resnet34\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader\n\n\nmean = (0.5071, 0.4867, 0.4408)\nstd  = (0.2675, 0.2565, 0.2761)\nbatch_size = 128\nnum_workers = 0\npin_mem = True\n\n@torch.no_grad()\ndef evaluate(model, loader, device):\n    model.eval()\n    correct = total = 0\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        logits = model(x)\n        pred = logits.argmax(1)\n        correct += (pred == y).sum().item()\n        total += y.size(0)\n    return 100.0 * correct / total\n\n\ntorch.manual_seed(27)\nnp.random.seed(27)\n\ntorch.cuda.manual_seed_all(27)\ntorch.backends.cudnn.deterministic = False\ntorch.backends.cudnn.benchmark = True\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:18:59.739645Z","iopub.execute_input":"2025-08-19T10:18:59.740188Z","iopub.status.idle":"2025-08-19T10:18:59.868461Z","shell.execute_reply.started":"2025-08-19T10:18:59.740159Z","shell.execute_reply":"2025-08-19T10:18:59.867862Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"stages = [(r) for r in [(32, 240)]]\ndataloader_dict = {}\n\nfor resolution, _ in stages:\n    train_tf = transforms.Compose([\n        transforms.RandomCrop(resolution, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean, std),\n    ])\n\n    train_set = datasets.CIFAR100('./data', train=True, download=True, transform=train_tf)\n    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True,\n                              num_workers=num_workers, pin_memory=pin_mem)\n\n    dataloader_dict[resolution] = {'train': train_loader}\n\n\ntest_tf = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std),\n])\ntest_set = datasets.CIFAR100('./data', train=False, download=True, transform=test_tf)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False,\n                         num_workers=num_workers, pin_memory=pin_mem)\n\n\nresolution, _ = stages[0]          # (32, 240)\ntrain_loader = dataloader_dict[resolution]['train']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:18:59.870429Z","iopub.execute_input":"2025-08-19T10:18:59.870646Z","iopub.status.idle":"2025-08-19T10:19:01.689534Z","shell.execute_reply.started":"2025-08-19T10:18:59.870628Z","shell.execute_reply":"2025-08-19T10:19:01.688994Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# learning_rate is divided by 10 \n# ---------------------------\n# Training loop\n# ---------------------------\n\ndef kd_loss(student_logits, teacher_logits, labels, T=4.0, alpha=0.9): \n    \"\"\"\n    alpha = 0.1 as per the github repo\n    Compute KD loss = Î± * KD + (1-Î±) * CE\n    T = temperature\n    Î± = weight for soft distillation loss\n    \"\"\"\n    # Hard-label loss\n    ce = F.cross_entropy(student_logits, labels)\n    kd = F.kl_div(\n        F.log_softmax(student_logits / T, dim=1),\n        F.softmax(teacher_logits / T, dim=1),\n        reduction=\"batchmean\") * (T * T)\n    \n    return (1 - alpha) * ce + alpha * kd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:19:01.690296Z","iopub.execute_input":"2025-08-19T10:19:01.690497Z","iopub.status.idle":"2025-08-19T10:19:01.695128Z","shell.execute_reply.started":"2025-08-19T10:19:01.690480Z","shell.execute_reply":"2025-08-19T10:19:01.694552Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def train_via_KD(t_model, s_model, train_loader, test_loader, device,\n                 epochs=240, base_lr=0.05, wd=5e-4, milestones=(150,180,210),\n                 T=4.0, alpha=0.9, save_path=\"student_kd.pth\"):\n\n    # Freeze teacher\n    t_model.to(device).eval()\n    for p in t_model.parameters():\n        p.requires_grad = False\n\n    s_model = s_model.to(device)\n\n    optimizer = optim.SGD(s_model.parameters(), lr=base_lr, momentum=0.9, weight_decay=wd)\n    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=list(milestones), gamma=0.1)\n\n    best_test = -1.0\n    for e in range(1, epochs + 1):\n        s_model.train()\n        running_loss, correct, total = 0.0, 0, 0\n\n        for imgs, labels in tqdm(train_loader, desc=f\"Epoch {e}/{epochs}\"):\n            imgs, labels = imgs.to(device), labels.to(device)\n\n            with torch.no_grad():\n                t_logits = t_model(imgs)\n\n            s_logits = s_model(imgs)\n            loss = kd_loss(s_logits, t_logits, labels, T=T, alpha=alpha)\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item() * imgs.size(0)\n            preds = s_logits.argmax(1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n\n        scheduler.step()\n        train_loss = running_loss / total\n        train_acc  = 100.0 * correct / total\n        test_acc   = evaluate(s_model, test_loader, device)\n\n        print(f\"Epoch {e:3d}/{epochs} | loss {train_loss:.3f} | train {train_acc:5.2f}% | test {test_acc:5.2f}%\")\n\n        if test_acc > best_test:\n            best_test = test_acc\n            to_save = s_model.module.state_dict() if isinstance(s_model, torch.nn.DataParallel) else s_model.state_dict()\n            torch.save(to_save, save_path)\n            print(f\"  â†³ Saved best @ epoch {e} (test {best_test:.2f}%) â†’ {save_path}\")\n\n    print(f\"âœ… KD training finished. Best Test Acc: {best_test:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:19:01.695973Z","iopub.execute_input":"2025-08-19T10:19:01.696198Z","iopub.status.idle":"2025-08-19T10:19:01.713352Z","shell.execute_reply.started":"2025-08-19T10:19:01.696180Z","shell.execute_reply":"2025-08-19T10:19:01.712665Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nteacher = resnet56(num_classes = 100)\nt_ckpt  = torch.load(\"/kaggle/input/resnet-56/ckpt_epoch_240.pth\", map_location=device, weights_only=False)\nteacher.load_state_dict(t_ckpt['model'] if 'model' in t_ckpt else t_ckpt)\n\nstudent = resnet20(num_classes=100)\n\ntrain_via_KD(teacher, student, train_loader, test_loader, device, save_path= \"56_t-20_s.pth\")","metadata":{"execution":{"iopub.status.busy":"2025-08-17T16:03:55.221023Z","iopub.execute_input":"2025-08-17T16:03:55.221245Z","iopub.status.idle":"2025-08-17T16:10:21.743628Z","shell.execute_reply.started":"2025-08-17T16:03:55.221229Z","shell.execute_reply":"2025-08-17T16:10:21.742137Z"}}},{"cell_type":"markdown","source":"\nteacher = resnet110(num_classes = 100)\nt_ckpt  = torch.load(\"/kaggle/input/resnet-110/ckpt_epoch_240.pth\", map_location=device, weights_only=False)\nteacher.load_state_dict(t_ckpt['model'] if 'model' in t_ckpt else t_ckpt)\n\nstudent = resnet20(num_classes=100)\n\ntrain_via_KD(teacher, student, train_loader, test_loader, device, save_path= \"110_t-20_s.pth\")","metadata":{"execution":{"iopub.status.busy":"2025-08-17T16:10:21.744538Z","iopub.status.idle":"2025-08-17T16:10:21.744813Z","shell.execute_reply.started":"2025-08-17T16:10:21.744689Z","shell.execute_reply":"2025-08-17T16:10:21.744704Z"}}},{"cell_type":"markdown","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nteacher = resnet110(num_classes = 100)\nt_ckpt  = torch.load(\"/kaggle/input/resnet-110/ckpt_epoch_240.pth\", map_location=device, weights_only=False)\nteacher.load_state_dict(t_ckpt['model'] if 'model' in t_ckpt else t_ckpt)\n\nstudent = resnet32_basic(num_classes=100)\n\ntrain_via_KD(teacher, student, train_loader, test_loader, device, save_path= \"110_t-32_s.pth\")","metadata":{"execution":{"iopub.status.busy":"2025-08-17T16:10:21.745950Z","iopub.status.idle":"2025-08-17T16:10:21.746237Z","shell.execute_reply.started":"2025-08-17T16:10:21.746097Z","shell.execute_reply":"2025-08-17T16:10:21.746114Z"}}},{"cell_type":"markdown","source":"# DIFF KD training - latent diffusion for training\n","metadata":{}},{"cell_type":"code","source":"import math\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom tqdm.auto import tqdm\n\n\ndef sinusoidal_embedding(t: torch.Tensor, dim: int) -> torch.Tensor:\n    \"\"\"[B] -> [B, dim]\"\"\"\n    device = t.device\n    half = dim // 2\n    freqs = torch.exp(-math.log(10000) * torch.arange(half, device=device).float() / max(half,1))\n    args = t.float().unsqueeze(1) * freqs.unsqueeze(0)\n    emb = torch.cat([torch.sin(args), torch.cos(args)], dim=1)\n    if dim % 2: emb = F.pad(emb, (0,1))\n    return emb\n\n\n@torch.no_grad()\ndef ddim_update(x_t, eps_pred, abar_t, abar_prev):\n    # x0 = (x_t - sqrt(1-abar_t)*eps) / sqrt(abar_t)\n    x0 = (x_t - torch.sqrt(1.0 - abar_t) * eps_pred) / torch.sqrt(abar_t)\n    x_prev = torch.sqrt(abar_prev) * x0 + torch.sqrt(1.0 - abar_prev) * eps_pred\n    return x_prev\n\nclass DiffSchedule:\n    def __init__(self, T=1000, device='cuda'):\n        # linear beta works well for features/logits here\n        betas = torch.linspace(1e-4, 2e-2, T, device=device)\n        alphas = 1.0 - betas\n        self.abar = torch.cumprod(alphas, dim=0)              # [T]\n        self.T = T\n        self.device = device\n\n    def abar_at(self, t):  # t: Long[B] or scalar int\n        return self.abar[t]\n\n# ---------- Tiny denoisers ----------\nclass Bottleneck2D(nn.Module):\n    def __init__(self, c, hidden=None):\n        super().__init__()\n        h = hidden or max(32, c // 4)\n        self.net = nn.Sequential(\n            nn.Conv2d(c, h, 1, bias=False), nn.BatchNorm2d(h), nn.ReLU(inplace=True),\n            nn.Conv2d(h, h, 3, padding=1, bias=False), nn.BatchNorm2d(h), nn.ReLU(inplace=True),\n            nn.Conv2d(h, c, 1, bias=False), nn.BatchNorm2d(c)\n        )\n        self.act = nn.ReLU(inplace=True)\n    def forward(self, x):  # residual\n        return self.act(self.net(x) + x)\n\nclass DiffusionDenoiser2D(nn.Module):\n    \"\"\"Î¦_theta for feature maps [B,C,H,W]. Two bottlenecks + time conditioning.\"\"\"\n    def __init__(self, c, t_dim=128):\n        super().__init__()\n        self.t_mlp = nn.Sequential(nn.Linear(t_dim, 2*c), nn.SiLU(), nn.Linear(2*c, 2*c))\n        self.bn = nn.BatchNorm2d(c)\n        self.block1 = Bottleneck2D(c)\n        self.block2 = Bottleneck2D(c)\n        self.proj = nn.Conv2d(c, c, 1)\n        self.t_dim = t_dim\n        nn.init.zeros_(self.proj.weight)\n\n    def forward(self, zt, t):\n        # time -> FiLM\n        temb = self.t_mlp(sinusoidal_embedding(t, self.t_dim))  # [B, 2C]\n        B, C, H, W = zt.shape\n        gamma, beta = temb[:, :C].view(B,C,1,1), temb[:, C:].view(B,C,1,1)\n        h = self.bn(zt) * (1 + gamma) + beta\n        h = self.block1(h)\n        h = self.block2(h)\n        eps = self.proj(h)\n        return eps\n\nclass DiffusionDenoiser1D(nn.Module):\n    \"\"\"MLP denoiser for logits [B,num_classes].\"\"\"\n    def __init__(self, d, t_dim=64, hidden=512):\n        super().__init__()\n        self.t_mlp = nn.Sequential(nn.Linear(t_dim, hidden), nn.SiLU(), nn.Linear(hidden, hidden))\n        self.fc1 = nn.Linear(d, hidden)\n        self.fc2 = nn.Linear(hidden, hidden)\n        self.out = nn.Linear(hidden, d)\n        nn.init.zeros_(self.out.weight)\n\n        self.t_dim = t_dim\n\n    def forward(self, zt, t):\n        temb = self.t_mlp(sinusoidal_embedding(t, self.t_dim))  # [B,H]\n        h = self.fc1(zt) + temb\n        h = F.silu(h)\n        h = F.silu(self.fc2(h))\n        eps = self.out(h)\n        return eps\n\n# ---------- Noise adapters (Î³) ----------\nclass NoiseAdapter2D(nn.Module):\n    def __init__(self, c):\n        super().__init__()\n        self.conv = nn.Conv2d(c, max(8, c//8), 1)\n        self.head = nn.Sequential(\n            nn.AdaptiveAvgPool2d(1),\n            nn.Flatten(),\n            nn.Linear(max(8, c//8), 1)\n        )\n    def forward(self, z):    # [B,C,H,W] -> [B,1,1,1] in (0,1)\n        g = torch.sigmoid(self.head(F.silu(self.conv(z))))\n        return g.view(-1,1,1,1)\n\nclass NoiseAdapter1D(nn.Module):\n    def __init__(self, d):\n        super().__init__()\n        self.net = nn.Sequential(nn.Linear(d, max(8, d//8)), nn.SiLU(), nn.Linear(max(8, d//8), 1))\n    def forward(self, z):    # [B,D] -> [B,1] in (0,1)\n        return torch.sigmoid(self.net(z))\n\n# ---------- DiffKD trainer ----------\nclass DiffKDTrainer(nn.Module):\n    def __init__(self, teacher, student, num_classes=100, device='cuda',\n                 T=1000, t_start=500, nfe=5, lambda_diff=1.0, lambda_kd=1.0, lambda_kd_logits=1.0):\n        super().__init__()\n        self.teacher = teacher.eval()                # frozen\n        for p in self.teacher.parameters(): p.requires_grad = False\n\n        self.student = student\n\n        self.device = device\n        self.sch = DiffSchedule(T=T, device=device)\n        self.t_start = t_start\n        self.nfe = nfe\n\n        # Feature channels (before avgpool) for your ResNet: last stage is 64 on CIFAR\n        self.feat_c = 64\n\n        # Denoisers\n        self.phi_feat = DiffusionDenoiser2D(self.feat_c).to(device)\n        self.phi_logit = DiffusionDenoiser1D(num_classes).to(device)\n\n        # Noise adapters (Î³)\n        self.adapt_feat = NoiseAdapter2D(self.feat_c).to(device)\n        self.adapt_logit = NoiseAdapter1D(num_classes).to(device)\n\n        # in case teacher/student channels mismatch, add a 1Ã—1 proj for student feature\n        self.stu_proj = nn.Conv2d(self.feat_c, self.feat_c, 1).to(device)\n\n        self.lambda_diff = lambda_diff\n        self.lambda_kd = lambda_kd\n        self.lambda_kd_logits = lambda_kd_logits\n\n    def get_feats_logits(self, model, x):\n        feats, logits = model(x, is_feat=True)   # feats: [f0,f1,f2,f3,f4]; we need f3\n        f3 = feats[3]                            # [B, C=64, H=8, W=8] on CIFAR\n        return f3, logits\n\n    def train_step(self, batch, optimizer):\n        x, y = batch\n        x = x.to(self.device); y = y.to(self.device)\n\n        # ----- teacher inference (no grad) -----\n        with torch.no_grad():\n            t_feat, t_logit = self.get_feats_logits(self.teacher, x)\n            # losses use these as \"clean\" targets\n            t_feat_detached = t_feat.detach()\n            t_logit_detached = t_logit.detach()\n\n        # ----- student forward -----\n        s_feat, s_logit = self.get_feats_logits(self.student, x)\n        s_feat = self.stu_proj(s_feat)\n\n        # ----- (A) Train denoisers: noise-pred on teacher outputs -----\n        B = x.size(0)\n        # sample random diffusion times for noise-pred training\n        t_rand = torch.randint(1, self.sch.T, (B,), device=self.device)\n        abar_t = self.sch.abar_at(t_rand).view(B,1,1,1)\n        eps_feat = torch.randn_like(t_feat_detached)\n        zt_feat = torch.sqrt(abar_t) * t_feat_detached + torch.sqrt(1.0 - abar_t) * eps_feat\n        eps_hat_feat = self.phi_feat(zt_feat, t_rand)\n        loss_diff_feat = F.mse_loss(eps_hat_feat, eps_feat)\n\n        # logits branch\n        abar_tl = self.sch.abar_at(t_rand).view(B,1)\n        eps_logit = torch.randn_like(t_logit_detached)\n        zt_logit = torch.sqrt(abar_tl) * t_logit_detached + torch.sqrt(1.0 - abar_tl) * eps_logit\n        eps_hat_logit = self.phi_logit(zt_logit, t_rand)\n        loss_diff_logit = F.mse_loss(eps_hat_logit, eps_logit)\n\n        loss_diff = loss_diff_feat + loss_diff_logit\n\n        # ----- (B) Denoise student -> KD against teacher -----\n        # start from t_start and do nfe jumps down to 0\n        with torch.no_grad():\n            # precompute the time grid\n            steps = torch.linspace(self.t_start, 0, self.nfe+1, device=self.device).long()\n        # Feature branch\n        gamma_feat = self.adapt_feat(s_feat)                  # [B,1,1,1]\n        z = gamma_feat * s_feat + (1.0 - gamma_feat) * torch.randn_like(s_feat)\n        for i in range(self.nfe):\n            t_cur = steps[i].expand(B)\n            t_prev = steps[i+1].expand(B)\n            abar_cur = self.sch.abar_at(t_cur).view(B,1,1,1)\n            abar_prev = self.sch.abar_at(t_prev).view(B,1,1,1).clamp(min=1e-6)\n            eps = self.phi_feat(z, t_cur)\n            z = ddim_update(z, eps, abar_cur, abar_prev)\n        s_feat_denoised = z\n        loss_kd_feat = F.mse_loss(s_feat_denoised, t_feat_detached)\n\n        # Logits branch\n        gamma_log = self.adapt_logit(s_logit)                 # [B,1]\n        z = gamma_log * s_logit + (1.0 - gamma_log) * torch.randn_like(s_logit)\n        for i in range(self.nfe):\n            t_cur = steps[i].expand(B)\n            t_prev = steps[i+1].expand(B)\n            abar_cur = self.sch.abar_at(t_cur).view(B,1)\n            abar_prev = self.sch.abar_at(t_prev).view(B,1).clamp(min=1e-6)\n            eps = self.phi_logit(z, t_cur)\n            # 1D version of update\n            x0 = (z - torch.sqrt(1.0 - abar_cur) * eps) / torch.sqrt(abar_cur)\n            z  = torch.sqrt(abar_prev) * x0 + torch.sqrt(1.0 - abar_prev) * eps\n        s_logit_denoised = z\n        # logits KD with KL (temperature=1 per paper baseline on logits)\n        loss_kd_log = F.kl_div(\n            F.log_softmax(s_logit_denoised, dim=1),\n            F.softmax(t_logit_detached, dim=1),\n            reduction=\"batchmean\"\n        )\n\n        # ----- (C) Task loss (CE) -----\n        loss_task = F.cross_entropy(s_logit, y)\n\n        # ----- total -----\n        loss = loss_task + self.lambda_diff * loss_diff + self.lambda_kd * loss_kd_feat + self.lambda_kd_logits * loss_kd_log\n\n        optimizer.zero_grad(set_to_none=True)\n        loss.backward()\n        optimizer.step()\n\n        with torch.no_grad():\n            pred = s_logit.argmax(1)\n            acc = (pred == y).float().mean().item() * 100.0\n\n        return {\n            \"loss_total\": float(loss),\n            \"loss_task\": float(loss_task),\n            \"loss_diff\": float(loss_diff),\n            \"loss_kd_feat\": float(loss_kd_feat),\n            \"loss_kd_log\": float(loss_kd_log),\n            \"acc\": acc,\n        }\n\n# -------------------------\n# Training loop for DiffKD\n# -------------------------\ndef train_via_DiffKD(teacher, student, train_loader, test_loader, device,\n                     epochs=240, base_lr=0.05, wd=5e-4,\n                     t_start=500, nfe=5, save_path=\"student_diffkd.pth\"):\n    torch.cuda.empty_cache()\n    trainer = DiffKDTrainer(\n        teacher.to(device),\n        student.to(device),\n        num_classes=100,\n        device=device,\n        T=1000,\n        t_start=t_start,\n        nfe=nfe,\n        lambda_diff=1.0,         # Î»1 (diffusion noise-pred losses)\n        lambda_kd=1.0,           # Î»3 on feature KD (MSE)\n        lambda_kd_logits=1.0     # logits KD (KL)\n    )\n\n    # optimize student + denoisers + adapters + proj (teacher frozen)\n    params = list(trainer.student.parameters()) + \\\n             list(trainer.phi_feat.parameters()) + list(trainer.phi_logit.parameters()) + \\\n             list(trainer.adapt_feat.parameters()) + list(trainer.adapt_logit.parameters()) + \\\n             list(trainer.stu_proj.parameters())\n\n    optimizer = torch.optim.SGD(params, lr=base_lr, momentum=0.9, weight_decay=wd)\n    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150,180,210], gamma=0.1)\n\n    @torch.no_grad()\n    def evaluate(model, loader):\n        model.eval()\n        correct = total = 0\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            logits = model(x)\n            pred = logits.argmax(1)\n            correct += (pred == y).sum().item()\n            total += y.size(0)\n        return 100.0 * correct / total\n\n    best = -1.0\n    for e in range(1, epochs+1):\n        trainer.train()\n        running = {\"loss_total\":0,\"acc\":0}\n        n = 0\n        for batch in tqdm(train_loader, desc=f\"[DiffKD] Epoch {e}/{epochs}\"):\n            stats = trainer.train_step(batch, optimizer)\n            bs = batch[0].size(0)\n            n += bs\n            running[\"loss_total\"] += stats[\"loss_total\"] * bs\n            running[\"acc\"] += stats[\"acc\"] * bs\n\n        scheduler.step()\n        tr_loss = running[\"loss_total\"]/n\n        tr_acc  = running[\"acc\"]/n\n        te_acc  = evaluate(trainer.student, test_loader)\n\n        print(f\"Epoch {e:3d}/{epochs} | loss {tr_loss:.3f} | train {tr_acc:5.2f}% | test {te_acc:5.2f}%\")\n\n        if te_acc > best:\n            best = te_acc\n            state = trainer.student.module.state_dict() if isinstance(trainer.student, nn.DataParallel) else trainer.student.state_dict()\n            torch.save(state, save_path)\n            print(f\"  â†³ Saved best @ epoch {e} (test {best:.2f}%) â†’ {save_path}\")\n\n    print(f\"âœ… DiffKD finished. Best Test Acc: {best:.2f}%\")\n    return best\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:19:01.714186Z","iopub.execute_input":"2025-08-19T10:19:01.714426Z","iopub.status.idle":"2025-08-19T10:19:01.913376Z","shell.execute_reply.started":"2025-08-19T10:19:01.714405Z","shell.execute_reply":"2025-08-19T10:19:01.912688Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# 1) Teacher\nteacher = resnet56(num_classes=100)\nt_ckpt  = torch.load(\"/kaggle/input/resnet-56/ckpt_epoch_240.pth\", map_location=device, weights_only=False)\nteacher.load_state_dict(t_ckpt['model'] if 'model' in t_ckpt else t_ckpt)\n\n# 2) Student\nstudent = resnet20(num_classes=100)\n\n# 3) Train with DiffKD (feature+logits, NFEs=5, t_start=500)\ntrain_via_DiffKD(\n    teacher, student,\n    train_loader, test_loader, device,\n    epochs=240, base_lr=0.05, wd=5e-4,\n    t_start=500, nfe=5,\n    save_path=\"rn20_from_rn56_DiffKD.pth\"\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-19T10:19:01.914080Z","iopub.execute_input":"2025-08-19T10:19:01.914370Z","iopub.status.idle":"2025-08-19T12:42:51.685689Z","shell.execute_reply.started":"2025-08-19T10:19:01.914340Z","shell.execute_reply":"2025-08-19T12:42:51.685021Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 1/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5dd1a351300411795e4a9dfa5887478"}},"metadata":{}},{"name":"stdout","text":"Epoch   1/240 | loss 18.687 | train  7.53% | test 12.48%\n  â†³ Saved best @ epoch 1 (test 12.48%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 2/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b783a02e89a044fca936824a9c8fa700"}},"metadata":{}},{"name":"stdout","text":"Epoch   2/240 | loss 16.571 | train 16.80% | test 19.78%\n  â†³ Saved best @ epoch 2 (test 19.78%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 3/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce55ba26d9254b6c8377bbb329edc8b6"}},"metadata":{}},{"name":"stdout","text":"Epoch   3/240 | loss 15.853 | train 26.22% | test 26.87%\n  â†³ Saved best @ epoch 3 (test 26.87%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 4/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"148df27e3ddc4caa9947de197444e43a"}},"metadata":{}},{"name":"stdout","text":"Epoch   4/240 | loss 15.328 | train 33.84% | test 28.85%\n  â†³ Saved best @ epoch 4 (test 28.85%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 5/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"837333dfbdb8459484c21971304f40bc"}},"metadata":{}},{"name":"stdout","text":"Epoch   5/240 | loss 14.951 | train 39.18% | test 38.87%\n  â†³ Saved best @ epoch 5 (test 38.87%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 6/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b488efa8090b41879025799faf89f2fe"}},"metadata":{}},{"name":"stdout","text":"Epoch   6/240 | loss 14.636 | train 43.13% | test 35.69%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 7/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34446e031a89487080f2c72d304d8a9d"}},"metadata":{}},{"name":"stdout","text":"Epoch   7/240 | loss 14.401 | train 45.85% | test 41.83%\n  â†³ Saved best @ epoch 7 (test 41.83%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 8/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7b8be625554b09a45357feaac8f4ae"}},"metadata":{}},{"name":"stdout","text":"Epoch   8/240 | loss 14.209 | train 48.34% | test 43.55%\n  â†³ Saved best @ epoch 8 (test 43.55%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 9/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a99856f4ea344d08be4ecd1cbe21a43a"}},"metadata":{}},{"name":"stdout","text":"Epoch   9/240 | loss 14.057 | train 50.17% | test 45.37%\n  â†³ Saved best @ epoch 9 (test 45.37%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 10/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"018f675832014a978ee68d95ed303522"}},"metadata":{}},{"name":"stdout","text":"Epoch  10/240 | loss 13.949 | train 51.65% | test 47.16%\n  â†³ Saved best @ epoch 10 (test 47.16%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 11/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b1109c0453440f6a74d7cf5cf72a172"}},"metadata":{}},{"name":"stdout","text":"Epoch  11/240 | loss 13.882 | train 53.29% | test 46.48%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 12/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd3c433c61fa40a9af30a84362d56778"}},"metadata":{}},{"name":"stdout","text":"Epoch  12/240 | loss 13.857 | train 54.12% | test 50.99%\n  â†³ Saved best @ epoch 12 (test 50.99%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 13/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31535bee445d41838222011642360d3b"}},"metadata":{}},{"name":"stdout","text":"Epoch  13/240 | loss 13.861 | train 55.11% | test 49.27%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 14/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f0f2d6a48bb4de5bb1064b5b481ac51"}},"metadata":{}},{"name":"stdout","text":"Epoch  14/240 | loss 13.820 | train 56.17% | test 48.84%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 15/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb529f1c2a6547d79f1d44ccf14f8705"}},"metadata":{}},{"name":"stdout","text":"Epoch  15/240 | loss 13.807 | train 56.72% | test 49.81%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 16/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b8108d0fa38485abc52d45b3c652162"}},"metadata":{}},{"name":"stdout","text":"Epoch  16/240 | loss 13.811 | train 57.40% | test 53.33%\n  â†³ Saved best @ epoch 16 (test 53.33%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 17/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e37dbfb2904445fb7b03970388dc5d9"}},"metadata":{}},{"name":"stdout","text":"Epoch  17/240 | loss 13.764 | train 57.81% | test 51.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 18/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c81ecca86a2f4c18bbc97b2c4e673e75"}},"metadata":{}},{"name":"stdout","text":"Epoch  18/240 | loss 13.717 | train 58.32% | test 49.07%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 19/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a7261369f354ce8bac9dd5c4f218012"}},"metadata":{}},{"name":"stdout","text":"Epoch  19/240 | loss 13.637 | train 59.00% | test 53.39%\n  â†³ Saved best @ epoch 19 (test 53.39%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 20/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50466f8c500943f8a18d58634fabe4e3"}},"metadata":{}},{"name":"stdout","text":"Epoch  20/240 | loss 13.601 | train 59.26% | test 52.23%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 21/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c22074bf4cdd45ea801e9b3cd60708d5"}},"metadata":{}},{"name":"stdout","text":"Epoch  21/240 | loss 13.577 | train 59.30% | test 49.38%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 22/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbdf4586d8864b76a2fa8151bed487dc"}},"metadata":{}},{"name":"stdout","text":"Epoch  22/240 | loss 13.500 | train 59.86% | test 51.09%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 23/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"007534ce236c4ef2b02fb1696837ee3a"}},"metadata":{}},{"name":"stdout","text":"Epoch  23/240 | loss 13.451 | train 60.14% | test 52.03%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 24/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdbc07f9c9714fd79c15d487c5113b12"}},"metadata":{}},{"name":"stdout","text":"Epoch  24/240 | loss 13.448 | train 60.52% | test 51.60%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 25/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8379358fd79477889c302a64054dd49"}},"metadata":{}},{"name":"stdout","text":"Epoch  25/240 | loss 13.371 | train 60.77% | test 52.75%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 26/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8dd3db0fb26d43079a6cac325fc865bd"}},"metadata":{}},{"name":"stdout","text":"Epoch  26/240 | loss 13.337 | train 60.73% | test 53.45%\n  â†³ Saved best @ epoch 26 (test 53.45%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 27/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"807a5a7be98749be81ef70420a1083e4"}},"metadata":{}},{"name":"stdout","text":"Epoch  27/240 | loss 13.319 | train 61.46% | test 54.56%\n  â†³ Saved best @ epoch 27 (test 54.56%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 28/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b01205af11e4b03903483ffb3c5e252"}},"metadata":{}},{"name":"stdout","text":"Epoch  28/240 | loss 13.286 | train 61.66% | test 52.37%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 29/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"912107fdc13544e99cddb5d92507b330"}},"metadata":{}},{"name":"stdout","text":"Epoch  29/240 | loss 13.231 | train 61.41% | test 52.54%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 30/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9b2866261fab40c0ba4413cb89c12a41"}},"metadata":{}},{"name":"stdout","text":"Epoch  30/240 | loss 13.195 | train 61.98% | test 52.04%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 31/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d01f3c208c87409ab0eff26383567d1c"}},"metadata":{}},{"name":"stdout","text":"Epoch  31/240 | loss 13.193 | train 62.07% | test 55.43%\n  â†³ Saved best @ epoch 31 (test 55.43%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 32/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5549e9a692624b51912a94e8e5875386"}},"metadata":{}},{"name":"stdout","text":"Epoch  32/240 | loss 13.162 | train 62.14% | test 48.01%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 33/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e411db951b62424f9c7271592e137bb3"}},"metadata":{}},{"name":"stdout","text":"Epoch  33/240 | loss 13.177 | train 62.51% | test 56.48%\n  â†³ Saved best @ epoch 33 (test 56.48%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 34/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdae8c2c491943b19c118eb938bffe0d"}},"metadata":{}},{"name":"stdout","text":"Epoch  34/240 | loss 13.175 | train 62.40% | test 55.83%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 35/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"04e0445a00a9477fa236b8af9753b1a4"}},"metadata":{}},{"name":"stdout","text":"Epoch  35/240 | loss 13.165 | train 62.36% | test 54.76%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 36/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"580d0339aeff4e2aaeee92920aec0ba6"}},"metadata":{}},{"name":"stdout","text":"Epoch  36/240 | loss 13.137 | train 62.88% | test 54.22%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 37/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"53b5f37011054247b97d417da9fb4cfb"}},"metadata":{}},{"name":"stdout","text":"Epoch  37/240 | loss 13.142 | train 62.99% | test 50.91%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 38/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"32b5536c8c8f4e04955d43b0796016ca"}},"metadata":{}},{"name":"stdout","text":"Epoch  38/240 | loss 13.116 | train 62.84% | test 54.23%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 39/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"181b0705ae854255b5bfd74a68ce5d41"}},"metadata":{}},{"name":"stdout","text":"Epoch  39/240 | loss 13.146 | train 63.09% | test 55.43%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 40/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3506b7b64cff4c9fa1ed93b107470909"}},"metadata":{}},{"name":"stdout","text":"Epoch  40/240 | loss 13.140 | train 63.49% | test 50.45%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 41/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"158cefaf0e454455a96eac1f70571521"}},"metadata":{}},{"name":"stdout","text":"Epoch  41/240 | loss 13.083 | train 63.05% | test 52.65%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 42/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b0aa5a75a924e62beb9880fbc0558d1"}},"metadata":{}},{"name":"stdout","text":"Epoch  42/240 | loss 13.103 | train 63.20% | test 52.57%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 43/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaba69c6aa58425a99282cd601e6255a"}},"metadata":{}},{"name":"stdout","text":"Epoch  43/240 | loss 13.115 | train 63.41% | test 56.37%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 44/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb717ed2d5cb4b0cbc46c19c8bf17f2f"}},"metadata":{}},{"name":"stdout","text":"Epoch  44/240 | loss 13.067 | train 63.71% | test 55.21%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 45/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"092dd6ccf635458193b93e01b61f1469"}},"metadata":{}},{"name":"stdout","text":"Epoch  45/240 | loss 13.077 | train 63.66% | test 55.07%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 46/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"507b7384a48c4a48bafa1d92fac4fb92"}},"metadata":{}},{"name":"stdout","text":"Epoch  46/240 | loss 13.064 | train 63.84% | test 56.50%\n  â†³ Saved best @ epoch 46 (test 56.50%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 47/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"81eaa206a45c4d90bf71f74f0c2c95e2"}},"metadata":{}},{"name":"stdout","text":"Epoch  47/240 | loss 13.092 | train 63.93% | test 52.73%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 48/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"693121895eb84a6c9a491bcd511003e9"}},"metadata":{}},{"name":"stdout","text":"Epoch  48/240 | loss 13.078 | train 64.00% | test 57.58%\n  â†³ Saved best @ epoch 48 (test 57.58%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 49/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c5ebc57ff8c4ee589fdb1503bce2e33"}},"metadata":{}},{"name":"stdout","text":"Epoch  49/240 | loss 13.067 | train 64.03% | test 54.62%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 50/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2e54ed55fe64de299b95085f82fd96b"}},"metadata":{}},{"name":"stdout","text":"Epoch  50/240 | loss 13.104 | train 63.73% | test 51.50%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 51/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5562590e4d7c48278f67a2c439bbdd9c"}},"metadata":{}},{"name":"stdout","text":"Epoch  51/240 | loss 13.079 | train 64.34% | test 55.47%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 52/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30b7cf0c95364a06aba5a06d890ba093"}},"metadata":{}},{"name":"stdout","text":"Epoch  52/240 | loss 13.094 | train 64.19% | test 55.93%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 53/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffe445287b1a458f8beb2e52125d26a4"}},"metadata":{}},{"name":"stdout","text":"Epoch  53/240 | loss 13.051 | train 64.27% | test 54.76%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 54/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6777b6ed1eb4426b7fc4691a8625885"}},"metadata":{}},{"name":"stdout","text":"Epoch  54/240 | loss 13.058 | train 64.36% | test 56.72%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 55/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a5b5b0e2c048db98cc0c1d1d4d88c8"}},"metadata":{}},{"name":"stdout","text":"Epoch  55/240 | loss 13.046 | train 64.23% | test 56.71%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 56/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"601b28eebb9a4b8ab3408dab30dc4d62"}},"metadata":{}},{"name":"stdout","text":"Epoch  56/240 | loss 13.057 | train 64.27% | test 56.40%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 57/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"712b200c59754e52b373269745ca6757"}},"metadata":{}},{"name":"stdout","text":"Epoch  57/240 | loss 13.063 | train 64.40% | test 56.36%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 58/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"250ab64072dd431f932885d10f86683b"}},"metadata":{}},{"name":"stdout","text":"Epoch  58/240 | loss 13.031 | train 64.64% | test 57.60%\n  â†³ Saved best @ epoch 58 (test 57.60%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 59/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"96a9694fe9c54ca8bf1c7f6b3c5a5260"}},"metadata":{}},{"name":"stdout","text":"Epoch  59/240 | loss 13.016 | train 64.86% | test 53.99%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 60/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bf356b2b50e46e8a63626b1430180d5"}},"metadata":{}},{"name":"stdout","text":"Epoch  60/240 | loss 13.013 | train 64.44% | test 56.70%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 61/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdb967f631f346f08b437234ad610bc0"}},"metadata":{}},{"name":"stdout","text":"Epoch  61/240 | loss 13.033 | train 64.27% | test 56.98%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 62/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9200c5024de142048c5cc2fc3fea41d4"}},"metadata":{}},{"name":"stdout","text":"Epoch  62/240 | loss 13.028 | train 64.60% | test 54.29%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 63/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ab84a4189f348c0931fa0481cd9e42f"}},"metadata":{}},{"name":"stdout","text":"Epoch  63/240 | loss 13.024 | train 64.82% | test 55.97%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 64/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65da648aca30408d9e85c732aabbd156"}},"metadata":{}},{"name":"stdout","text":"Epoch  64/240 | loss 13.007 | train 65.10% | test 54.83%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 65/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"413f7b16519f42f2b95b18831419c3a6"}},"metadata":{}},{"name":"stdout","text":"Epoch  65/240 | loss 13.034 | train 64.96% | test 53.57%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 66/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df3a861c697f4007ab4bf68ccfc7b94e"}},"metadata":{}},{"name":"stdout","text":"Epoch  66/240 | loss 13.010 | train 64.71% | test 54.84%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 67/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1f55c6ec1b8493081938ccdad62e5cc"}},"metadata":{}},{"name":"stdout","text":"Epoch  67/240 | loss 13.027 | train 64.81% | test 57.28%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 68/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b4f0e4d15264f1aaca919fca747b38f"}},"metadata":{}},{"name":"stdout","text":"Epoch  68/240 | loss 13.004 | train 65.19% | test 52.97%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 69/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bcebedb7aec24483a75d5e46b0b28a85"}},"metadata":{}},{"name":"stdout","text":"Epoch  69/240 | loss 12.984 | train 65.06% | test 54.06%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 70/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5556b47b2d94e70ba00228e6fe8378c"}},"metadata":{}},{"name":"stdout","text":"Epoch  70/240 | loss 13.003 | train 65.27% | test 54.97%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 71/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d005cc2face44a50a6f3cc736756f1e3"}},"metadata":{}},{"name":"stdout","text":"Epoch  71/240 | loss 12.959 | train 64.92% | test 53.49%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 72/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18df1e90fcf84e30bf0149480c671908"}},"metadata":{}},{"name":"stdout","text":"Epoch  72/240 | loss 12.998 | train 65.34% | test 56.79%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 73/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09d5a730c2874214a358c5ff9e36ede1"}},"metadata":{}},{"name":"stdout","text":"Epoch  73/240 | loss 12.987 | train 65.14% | test 57.52%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 74/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93a5f9e9949f47d5b43d124ddc0bf71e"}},"metadata":{}},{"name":"stdout","text":"Epoch  74/240 | loss 13.007 | train 64.98% | test 56.40%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 75/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a7b1199cda54603933ca0ea117a05fe"}},"metadata":{}},{"name":"stdout","text":"Epoch  75/240 | loss 12.962 | train 65.22% | test 56.34%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 76/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4af835c48c3e4b96b8363bf16f16142e"}},"metadata":{}},{"name":"stdout","text":"Epoch  76/240 | loss 12.978 | train 65.29% | test 54.38%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 77/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"baf12013b6724c87935c52290671ff2f"}},"metadata":{}},{"name":"stdout","text":"Epoch  77/240 | loss 12.956 | train 65.27% | test 54.94%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 78/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9260f18e879d4b16899028e79b6c9f0a"}},"metadata":{}},{"name":"stdout","text":"Epoch  78/240 | loss 12.970 | train 65.24% | test 54.66%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 79/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0cb31d2c211341fba665e4e11c2e167f"}},"metadata":{}},{"name":"stdout","text":"Epoch  79/240 | loss 12.938 | train 65.37% | test 53.65%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 80/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7c631a9290540778c64eafb93ae575b"}},"metadata":{}},{"name":"stdout","text":"Epoch  80/240 | loss 12.949 | train 65.23% | test 57.21%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 81/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22d0a8d033ec48d2be464bdddf2bef7d"}},"metadata":{}},{"name":"stdout","text":"Epoch  81/240 | loss 12.953 | train 65.44% | test 56.19%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 82/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"570cd323e20a4e96939edbfd8a5330dd"}},"metadata":{}},{"name":"stdout","text":"Epoch  82/240 | loss 12.971 | train 65.45% | test 53.96%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 83/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2fb209d080d64e33adbe65c453ca3761"}},"metadata":{}},{"name":"stdout","text":"Epoch  83/240 | loss 12.938 | train 65.30% | test 52.35%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 84/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d667875955d04926ae09dd951679ac49"}},"metadata":{}},{"name":"stdout","text":"Epoch  84/240 | loss 12.948 | train 65.46% | test 56.68%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 85/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c4d939bf1c043b7a18bbfcb5dc275d9"}},"metadata":{}},{"name":"stdout","text":"Epoch  85/240 | loss 12.918 | train 65.49% | test 58.30%\n  â†³ Saved best @ epoch 85 (test 58.30%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 86/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7bd94b0b87dc46bbb38592f1d88a185b"}},"metadata":{}},{"name":"stdout","text":"Epoch  86/240 | loss 12.980 | train 65.24% | test 56.40%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 87/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1496298ef236498c847f11e4c0a234fd"}},"metadata":{}},{"name":"stdout","text":"Epoch  87/240 | loss 12.970 | train 65.82% | test 52.95%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 88/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"425e06127e4248ceb6709a047e4f618f"}},"metadata":{}},{"name":"stdout","text":"Epoch  88/240 | loss 12.983 | train 65.50% | test 56.82%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 89/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4e0178985834628b856f094921bd818"}},"metadata":{}},{"name":"stdout","text":"Epoch  89/240 | loss 12.950 | train 65.54% | test 55.82%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 90/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fc9abde69ff4ef59a3e6f43c2f15e18"}},"metadata":{}},{"name":"stdout","text":"Epoch  90/240 | loss 12.931 | train 65.68% | test 55.67%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 91/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9bab5765b14c4619bd81fa7700343f4a"}},"metadata":{}},{"name":"stdout","text":"Epoch  91/240 | loss 12.951 | train 65.89% | test 57.19%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 92/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"61bbbc07b88c46c2a7e28b571b969e12"}},"metadata":{}},{"name":"stdout","text":"Epoch  92/240 | loss 12.954 | train 65.75% | test 56.01%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 93/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f4dbfa1758b5489692ac34613f1ed7c3"}},"metadata":{}},{"name":"stdout","text":"Epoch  93/240 | loss 12.949 | train 65.32% | test 55.19%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 94/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea7d598593764b9ca3ab20face7ad37f"}},"metadata":{}},{"name":"stdout","text":"Epoch  94/240 | loss 12.920 | train 65.58% | test 57.50%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 95/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f4fb87872f94b058d804e030384332a"}},"metadata":{}},{"name":"stdout","text":"Epoch  95/240 | loss 12.936 | train 65.72% | test 56.33%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 96/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7889291d3e52400a9d45895d33de03b2"}},"metadata":{}},{"name":"stdout","text":"Epoch  96/240 | loss 12.951 | train 65.61% | test 56.56%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 97/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e69fcd8902554bf9b8651395cd034881"}},"metadata":{}},{"name":"stdout","text":"Epoch  97/240 | loss 12.950 | train 65.69% | test 57.41%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 98/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a48b3dce783948399c72e6a6c7af1168"}},"metadata":{}},{"name":"stdout","text":"Epoch  98/240 | loss 12.930 | train 65.61% | test 57.23%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 99/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2daa6e809984087a1490fc70215eb7c"}},"metadata":{}},{"name":"stdout","text":"Epoch  99/240 | loss 12.950 | train 65.69% | test 56.18%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 100/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d5db209c3e448c1aa77722ec16605ad"}},"metadata":{}},{"name":"stdout","text":"Epoch 100/240 | loss 12.915 | train 65.99% | test 57.39%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 101/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c372d565a5294f6ba5929ec5003a999c"}},"metadata":{}},{"name":"stdout","text":"Epoch 101/240 | loss 12.919 | train 65.87% | test 56.24%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 102/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c35801a497b4b87ac5cd4f0b49bcd33"}},"metadata":{}},{"name":"stdout","text":"Epoch 102/240 | loss 12.935 | train 65.84% | test 56.09%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 103/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6031a051bd1343b89c99f68c2820e3c1"}},"metadata":{}},{"name":"stdout","text":"Epoch 103/240 | loss 12.898 | train 65.96% | test 52.42%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 104/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52b041f78d414eefa9676e61ca136dc1"}},"metadata":{}},{"name":"stdout","text":"Epoch 104/240 | loss 12.917 | train 65.64% | test 56.26%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 105/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2d2d5b8641194cfd885ff1dbebc852ef"}},"metadata":{}},{"name":"stdout","text":"Epoch 105/240 | loss 12.887 | train 65.92% | test 57.18%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 106/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca9815882964a759226d69aa4b30948"}},"metadata":{}},{"name":"stdout","text":"Epoch 106/240 | loss 12.931 | train 65.98% | test 56.13%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 107/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"209b93701fb94ff0baf88d79ff142fd6"}},"metadata":{}},{"name":"stdout","text":"Epoch 107/240 | loss 12.915 | train 65.90% | test 56.70%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 108/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97d36a5984448c8b73585216d00d3a1"}},"metadata":{}},{"name":"stdout","text":"Epoch 108/240 | loss 12.917 | train 65.85% | test 56.64%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 109/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c613159a0ea49098e1cb22b7c7f53e0"}},"metadata":{}},{"name":"stdout","text":"Epoch 109/240 | loss 12.945 | train 65.68% | test 53.68%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 110/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62e6e25a428e429b98fe13d0dee92904"}},"metadata":{}},{"name":"stdout","text":"Epoch 110/240 | loss 12.896 | train 65.97% | test 58.04%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 111/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"487d14610c1d4ff995dc40226be02026"}},"metadata":{}},{"name":"stdout","text":"Epoch 111/240 | loss 12.900 | train 66.03% | test 55.32%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 112/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a65c9f3dc704488b9be3e573c8853a5"}},"metadata":{}},{"name":"stdout","text":"Epoch 112/240 | loss 12.922 | train 66.06% | test 52.77%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 113/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0252692259854c29beb63b8d6baee959"}},"metadata":{}},{"name":"stdout","text":"Epoch 113/240 | loss 12.893 | train 65.98% | test 56.70%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 114/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93f883e0aaa84a28b45fc54da95418e4"}},"metadata":{}},{"name":"stdout","text":"Epoch 114/240 | loss 12.915 | train 66.16% | test 53.69%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 115/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e33beefd59c8488bb1f0296dc02fb1ae"}},"metadata":{}},{"name":"stdout","text":"Epoch 115/240 | loss 12.923 | train 66.00% | test 56.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 116/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f78deb4165f54ea98cfbe8e285cd1f8b"}},"metadata":{}},{"name":"stdout","text":"Epoch 116/240 | loss 12.916 | train 66.30% | test 55.45%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 117/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f60ba40d8c4405ba55b7725222bfdb1"}},"metadata":{}},{"name":"stdout","text":"Epoch 117/240 | loss 12.926 | train 65.98% | test 57.39%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 118/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d48d8c9bd72248019e02c9caf7a70cd6"}},"metadata":{}},{"name":"stdout","text":"Epoch 118/240 | loss 12.913 | train 66.06% | test 57.57%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 119/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebdd9b632ced4b81a5c3af1d8431b91d"}},"metadata":{}},{"name":"stdout","text":"Epoch 119/240 | loss 12.918 | train 66.32% | test 58.67%\n  â†³ Saved best @ epoch 119 (test 58.67%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 120/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"97ae26d118d24fbea0bbd984a55b0d7d"}},"metadata":{}},{"name":"stdout","text":"Epoch 120/240 | loss 12.915 | train 66.28% | test 58.31%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 121/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9840d1b838a34fcc81350387b96f241e"}},"metadata":{}},{"name":"stdout","text":"Epoch 121/240 | loss 12.919 | train 66.04% | test 55.80%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 122/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2cbe3ae6db9420894c82f8c83ab9f9a"}},"metadata":{}},{"name":"stdout","text":"Epoch 122/240 | loss 12.903 | train 66.10% | test 56.28%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 123/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"accb248997dc4898886f2344ac91f003"}},"metadata":{}},{"name":"stdout","text":"Epoch 123/240 | loss 12.922 | train 65.83% | test 55.54%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 124/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93a1ca04525d4125b6be500fb0be50bf"}},"metadata":{}},{"name":"stdout","text":"Epoch 124/240 | loss 12.904 | train 66.28% | test 59.08%\n  â†³ Saved best @ epoch 124 (test 59.08%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 125/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87df67e686374f379f68c0289b008542"}},"metadata":{}},{"name":"stdout","text":"Epoch 125/240 | loss 12.871 | train 66.19% | test 57.36%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 126/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e2aa95b814034c24a0f954ae9d4a3c2d"}},"metadata":{}},{"name":"stdout","text":"Epoch 126/240 | loss 12.889 | train 66.23% | test 57.43%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 127/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f2863ba62f3497c975ec7d4474bd26a"}},"metadata":{}},{"name":"stdout","text":"Epoch 127/240 | loss 12.889 | train 66.17% | test 54.51%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 128/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"341a87ce757b45a19708730ee778b616"}},"metadata":{}},{"name":"stdout","text":"Epoch 128/240 | loss 12.918 | train 66.17% | test 56.14%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 129/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac6354a4d9534bd0960cf3284095276d"}},"metadata":{}},{"name":"stdout","text":"Epoch 129/240 | loss 12.887 | train 66.36% | test 54.58%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 130/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33ed71f419d14e23838a52aa2ad04a1c"}},"metadata":{}},{"name":"stdout","text":"Epoch 130/240 | loss 12.926 | train 66.34% | test 55.45%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 131/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9dcbe3fe06a74debb17d64744655ad05"}},"metadata":{}},{"name":"stdout","text":"Epoch 131/240 | loss 12.958 | train 66.39% | test 54.41%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 132/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86061024c58340b6803da16ea4168bd5"}},"metadata":{}},{"name":"stdout","text":"Epoch 132/240 | loss 12.907 | train 66.41% | test 57.35%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 133/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd6ecb8cf4624a02ab8aded6f2a30f92"}},"metadata":{}},{"name":"stdout","text":"Epoch 133/240 | loss 12.889 | train 66.35% | test 56.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 134/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86bba1c7488547cfa4cfe437ceed37f0"}},"metadata":{}},{"name":"stdout","text":"Epoch 134/240 | loss 12.920 | train 66.24% | test 53.96%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 135/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d41455b92b454240a433e819ca9e2abb"}},"metadata":{}},{"name":"stdout","text":"Epoch 135/240 | loss 12.875 | train 66.38% | test 55.42%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 136/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"408d298b5dc64c9c9a3a72ab9816ffa8"}},"metadata":{}},{"name":"stdout","text":"Epoch 136/240 | loss 12.937 | train 66.65% | test 57.91%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 137/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05ef49c8ebfa4fa5bf3939be47b93575"}},"metadata":{}},{"name":"stdout","text":"Epoch 137/240 | loss 12.918 | train 66.34% | test 57.26%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 138/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0443a31085284b039b3fcb909bfa310a"}},"metadata":{}},{"name":"stdout","text":"Epoch 138/240 | loss 12.929 | train 66.22% | test 57.02%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 139/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0a7a6ba66164d989b98ed11e5154719"}},"metadata":{}},{"name":"stdout","text":"Epoch 139/240 | loss 12.899 | train 66.07% | test 55.52%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 140/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ba4186cd6e64c938ecb6246c1af667f"}},"metadata":{}},{"name":"stdout","text":"Epoch 140/240 | loss 12.886 | train 66.53% | test 53.23%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 141/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f46a70305de041a898ad9afccf1a530e"}},"metadata":{}},{"name":"stdout","text":"Epoch 141/240 | loss 12.929 | train 66.43% | test 58.50%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 142/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50283ceffe1c47ba98e3a2957cee20e6"}},"metadata":{}},{"name":"stdout","text":"Epoch 142/240 | loss 12.856 | train 66.45% | test 53.31%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 143/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"324140ddc9114d02a2a8d3ed42ce1f83"}},"metadata":{}},{"name":"stdout","text":"Epoch 143/240 | loss 12.922 | train 66.21% | test 58.27%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 144/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"280d40bc8e9d49e090baf730174944bc"}},"metadata":{}},{"name":"stdout","text":"Epoch 144/240 | loss 12.868 | train 66.41% | test 55.14%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 145/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"268b198028994e5395149d806b749a59"}},"metadata":{}},{"name":"stdout","text":"Epoch 145/240 | loss 12.854 | train 66.50% | test 53.32%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 146/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a3114c1a6a54e2ab2d752c3e13a195c"}},"metadata":{}},{"name":"stdout","text":"Epoch 146/240 | loss 12.868 | train 66.65% | test 57.04%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 147/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c847e01bdd7f498fa37eaaa51e49c7d0"}},"metadata":{}},{"name":"stdout","text":"Epoch 147/240 | loss 12.902 | train 66.53% | test 57.26%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 148/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7b8aa8def9874beab5c9fa4cfec47c28"}},"metadata":{}},{"name":"stdout","text":"Epoch 148/240 | loss 12.900 | train 66.30% | test 55.43%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 149/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecf5046155664d0daba1b9e37ed74239"}},"metadata":{}},{"name":"stdout","text":"Epoch 149/240 | loss 12.900 | train 66.44% | test 50.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 150/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aba6678107a34fc68a55baebba611894"}},"metadata":{}},{"name":"stdout","text":"Epoch 150/240 | loss 12.880 | train 66.41% | test 56.60%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 151/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c735eccaeb34bd1b40e230b32530636"}},"metadata":{}},{"name":"stdout","text":"Epoch 151/240 | loss 12.230 | train 74.21% | test 68.10%\n  â†³ Saved best @ epoch 151 (test 68.10%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 152/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a03b9125d00548a5bd967ea16e5e5fde"}},"metadata":{}},{"name":"stdout","text":"Epoch 152/240 | loss 12.092 | train 76.65% | test 68.19%\n  â†³ Saved best @ epoch 152 (test 68.19%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 153/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91be1d0e1ea542ce9977280b9e9d18f0"}},"metadata":{}},{"name":"stdout","text":"Epoch 153/240 | loss 12.097 | train 77.45% | test 68.67%\n  â†³ Saved best @ epoch 153 (test 68.67%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 154/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"21ffdd5a6d994a47bc27c9d280b1c937"}},"metadata":{}},{"name":"stdout","text":"Epoch 154/240 | loss 12.125 | train 77.81% | test 68.66%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 155/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6b17e537ee644dca484e03958ff196e"}},"metadata":{}},{"name":"stdout","text":"Epoch 155/240 | loss 12.137 | train 78.60% | test 69.06%\n  â†³ Saved best @ epoch 155 (test 69.06%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 156/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3494d8f718324c0ba848a3d5375dab51"}},"metadata":{}},{"name":"stdout","text":"Epoch 156/240 | loss 12.153 | train 78.89% | test 69.03%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 157/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ec6d2f02cf49470b942c91be0295a212"}},"metadata":{}},{"name":"stdout","text":"Epoch 157/240 | loss 12.207 | train 79.04% | test 69.22%\n  â†³ Saved best @ epoch 157 (test 69.22%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 158/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f06b141fc7a40a7a4bd3fe5767f069a"}},"metadata":{}},{"name":"stdout","text":"Epoch 158/240 | loss 12.225 | train 79.43% | test 69.26%\n  â†³ Saved best @ epoch 158 (test 69.26%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 159/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eb75794df1148a093fc247003dd71b1"}},"metadata":{}},{"name":"stdout","text":"Epoch 159/240 | loss 12.265 | train 79.65% | test 69.41%\n  â†³ Saved best @ epoch 159 (test 69.41%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 160/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"076844c1faa744c58e3304b1d160ae5f"}},"metadata":{}},{"name":"stdout","text":"Epoch 160/240 | loss 12.287 | train 80.06% | test 69.33%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 161/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e211a5e17c0e4629b0a14333741dac69"}},"metadata":{}},{"name":"stdout","text":"Epoch 161/240 | loss 12.320 | train 80.07% | test 69.55%\n  â†³ Saved best @ epoch 161 (test 69.55%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 162/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecec5f6d86f04f7f887065b3a07145b4"}},"metadata":{}},{"name":"stdout","text":"Epoch 162/240 | loss 12.357 | train 80.25% | test 69.27%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 163/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64e1b81f5e124deeaa69a8816a3108a9"}},"metadata":{}},{"name":"stdout","text":"Epoch 163/240 | loss 12.381 | train 80.54% | test 69.89%\n  â†³ Saved best @ epoch 163 (test 69.89%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 164/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"01d225ca342b435387360f6d9fd7cce1"}},"metadata":{}},{"name":"stdout","text":"Epoch 164/240 | loss 12.414 | train 80.72% | test 69.26%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 165/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c354832917674253b7d600730ca79da2"}},"metadata":{}},{"name":"stdout","text":"Epoch 165/240 | loss 12.433 | train 81.08% | test 69.75%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 166/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb47867f59474a2080589f683ab73138"}},"metadata":{}},{"name":"stdout","text":"Epoch 166/240 | loss 12.472 | train 80.87% | test 69.35%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 167/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c53da401ab14c82817515429a9c1ab3"}},"metadata":{}},{"name":"stdout","text":"Epoch 167/240 | loss 12.491 | train 81.15% | test 68.87%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 168/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7cb068883cbe4b9ea5ebf57619426dc9"}},"metadata":{}},{"name":"stdout","text":"Epoch 168/240 | loss 12.534 | train 81.31% | test 69.10%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 169/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37335bc1a1d04072a78fc850aadd2bde"}},"metadata":{}},{"name":"stdout","text":"Epoch 169/240 | loss 12.557 | train 81.33% | test 68.87%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 170/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e5b5be08a2f4173a4967b2ea7078dc1"}},"metadata":{}},{"name":"stdout","text":"Epoch 170/240 | loss 12.577 | train 81.45% | test 69.67%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 171/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64a562834a0f421aa574194688b7012f"}},"metadata":{}},{"name":"stdout","text":"Epoch 171/240 | loss 12.610 | train 81.55% | test 69.13%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 172/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"786c3fd27b264b30a74b72d43d138e64"}},"metadata":{}},{"name":"stdout","text":"Epoch 172/240 | loss 12.639 | train 82.02% | test 69.14%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 173/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4962ecd440ba4a0cb9009a0635227005"}},"metadata":{}},{"name":"stdout","text":"Epoch 173/240 | loss 12.657 | train 81.86% | test 68.80%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 174/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cca283259c1e42f699572d09513bbc82"}},"metadata":{}},{"name":"stdout","text":"Epoch 174/240 | loss 12.668 | train 82.04% | test 69.05%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 175/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b29745cd7154e37802440dfc220d1b0"}},"metadata":{}},{"name":"stdout","text":"Epoch 175/240 | loss 12.705 | train 82.10% | test 68.78%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 176/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8958dcaf5d964e9ab3a2efeae7b3e7ee"}},"metadata":{}},{"name":"stdout","text":"Epoch 176/240 | loss 12.739 | train 82.21% | test 68.87%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 177/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5830ace0ff044a4c9ac367f3ac27f620"}},"metadata":{}},{"name":"stdout","text":"Epoch 177/240 | loss 12.756 | train 82.16% | test 69.01%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 178/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"883430b9af3642ffa8afad2c99779ecf"}},"metadata":{}},{"name":"stdout","text":"Epoch 178/240 | loss 12.774 | train 82.39% | test 69.72%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 179/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"886afd7f8152412aa5a6edb8721e0108"}},"metadata":{}},{"name":"stdout","text":"Epoch 179/240 | loss 12.786 | train 82.31% | test 69.00%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 180/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4064f0892dfd47d39c3e3461bc6cd122"}},"metadata":{}},{"name":"stdout","text":"Epoch 180/240 | loss 12.825 | train 82.55% | test 68.68%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 181/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e340ed0b08f643709bcd356f789dcee3"}},"metadata":{}},{"name":"stdout","text":"Epoch 181/240 | loss 12.716 | train 84.07% | test 69.81%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 182/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a6b63037cdf4374965457e6a72283fb"}},"metadata":{}},{"name":"stdout","text":"Epoch 182/240 | loss 12.691 | train 84.61% | test 69.82%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 183/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28bfc5d19bc44ea9ab4ac2d6b671c470"}},"metadata":{}},{"name":"stdout","text":"Epoch 183/240 | loss 12.693 | train 84.69% | test 69.77%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 184/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db2ec6bf0c7248a28fe25ccc2454f452"}},"metadata":{}},{"name":"stdout","text":"Epoch 184/240 | loss 12.678 | train 84.71% | test 70.00%\n  â†³ Saved best @ epoch 184 (test 70.00%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 185/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ebe87e65adc641c7929b5f6ae2fe6c81"}},"metadata":{}},{"name":"stdout","text":"Epoch 185/240 | loss 12.688 | train 84.75% | test 69.98%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 186/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98164d5f793441dc995bea322eb55f31"}},"metadata":{}},{"name":"stdout","text":"Epoch 186/240 | loss 12.684 | train 84.91% | test 70.12%\n  â†³ Saved best @ epoch 186 (test 70.12%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 187/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e725ad6d4c554703903e131b894cbda3"}},"metadata":{}},{"name":"stdout","text":"Epoch 187/240 | loss 12.700 | train 84.97% | test 70.14%\n  â†³ Saved best @ epoch 187 (test 70.14%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 188/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5be2b421ff174a248caaa22c47dcaf91"}},"metadata":{}},{"name":"stdout","text":"Epoch 188/240 | loss 12.698 | train 84.93% | test 70.25%\n  â†³ Saved best @ epoch 188 (test 70.25%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 189/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64ebfd0fbcf3490f918650f2ed752343"}},"metadata":{}},{"name":"stdout","text":"Epoch 189/240 | loss 12.704 | train 84.96% | test 70.06%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 190/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ca52902bc714c6e92680819e5d2548c"}},"metadata":{}},{"name":"stdout","text":"Epoch 190/240 | loss 12.698 | train 85.07% | test 70.25%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 191/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c23036a9687d4a68872758aeca83e4c5"}},"metadata":{}},{"name":"stdout","text":"Epoch 191/240 | loss 12.703 | train 85.13% | test 70.17%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 192/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a26a2f27f8045b8b3946691b0b4f15c"}},"metadata":{}},{"name":"stdout","text":"Epoch 192/240 | loss 12.702 | train 85.42% | test 70.24%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 193/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d579f96755e41e5b43d0123a9f19c31"}},"metadata":{}},{"name":"stdout","text":"Epoch 193/240 | loss 12.711 | train 85.04% | test 69.98%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 194/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ed0c56c294e4618a0ccaac0b65b93b8"}},"metadata":{}},{"name":"stdout","text":"Epoch 194/240 | loss 12.714 | train 85.01% | test 69.95%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 195/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65fa0973ea6c46789d2bdde35e44a8c3"}},"metadata":{}},{"name":"stdout","text":"Epoch 195/240 | loss 12.717 | train 85.39% | test 70.12%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 196/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaee301f02c04e91aedc9c62537c2b23"}},"metadata":{}},{"name":"stdout","text":"Epoch 196/240 | loss 12.727 | train 85.20% | test 70.06%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 197/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb2b31e6c2df428eb518e09db481f4c5"}},"metadata":{}},{"name":"stdout","text":"Epoch 197/240 | loss 12.734 | train 85.29% | test 70.08%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 198/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"65ee091234244b2b8a84c13d9a6511e6"}},"metadata":{}},{"name":"stdout","text":"Epoch 198/240 | loss 12.728 | train 85.25% | test 70.05%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 199/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbb77534cd284d47865764064182b9fd"}},"metadata":{}},{"name":"stdout","text":"Epoch 199/240 | loss 12.723 | train 85.35% | test 70.09%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 200/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"536ee49594bd4b0f8d99e7037819f14e"}},"metadata":{}},{"name":"stdout","text":"Epoch 200/240 | loss 12.720 | train 85.59% | test 70.50%\n  â†³ Saved best @ epoch 200 (test 70.50%) â†’ rn20_from_rn56_DiffKD.pth\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 201/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67241d20668e43a9a66e693c2ec3328f"}},"metadata":{}},{"name":"stdout","text":"Epoch 201/240 | loss 12.734 | train 85.38% | test 70.12%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 202/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02e1993d399f42a49eff0be4a65e7c2b"}},"metadata":{}},{"name":"stdout","text":"Epoch 202/240 | loss 12.739 | train 85.40% | test 70.12%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 203/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e425ca29c15f41df8bbd606f5fcca566"}},"metadata":{}},{"name":"stdout","text":"Epoch 203/240 | loss 12.742 | train 85.47% | test 70.30%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 204/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0b5374f444149819ebf6aec30a7981d"}},"metadata":{}},{"name":"stdout","text":"Epoch 204/240 | loss 12.733 | train 85.39% | test 70.29%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 205/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cf2892c8d2b14dcbbf01ba0458c3129b"}},"metadata":{}},{"name":"stdout","text":"Epoch 205/240 | loss 12.751 | train 85.48% | test 70.38%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 206/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"891b2a1c210647ad874329bcfb96304a"}},"metadata":{}},{"name":"stdout","text":"Epoch 206/240 | loss 12.747 | train 85.50% | test 70.11%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 207/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76f478f9eb1043429665492cb78b9ba8"}},"metadata":{}},{"name":"stdout","text":"Epoch 207/240 | loss 12.751 | train 85.76% | test 70.17%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 208/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba154f8f95994d6a9942726e4d1cc9c6"}},"metadata":{}},{"name":"stdout","text":"Epoch 208/240 | loss 12.755 | train 85.69% | test 69.99%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 209/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d97f3ea3f38a4760b2d5138d2e62ad08"}},"metadata":{}},{"name":"stdout","text":"Epoch 209/240 | loss 12.759 | train 85.50% | test 70.11%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 210/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5278c615816c4e80b21d27296d2d91d7"}},"metadata":{}},{"name":"stdout","text":"Epoch 210/240 | loss 12.759 | train 85.63% | test 69.93%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 211/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8f56ac7a0fb4d97a6cd22bee7abb1d8"}},"metadata":{}},{"name":"stdout","text":"Epoch 211/240 | loss 12.743 | train 85.69% | test 70.10%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 212/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9eb5eb9d4ab45e8b420a51301e97279"}},"metadata":{}},{"name":"stdout","text":"Epoch 212/240 | loss 12.747 | train 85.72% | test 70.04%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 213/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a037773239d411b856240d3894d03d0"}},"metadata":{}},{"name":"stdout","text":"Epoch 213/240 | loss 12.745 | train 86.00% | test 69.89%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 214/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3962e0da6f6a433381706e87a89869f9"}},"metadata":{}},{"name":"stdout","text":"Epoch 214/240 | loss 12.752 | train 85.75% | test 70.05%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 215/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6be883f4689e49049bbf5d46ef79d232"}},"metadata":{}},{"name":"stdout","text":"Epoch 215/240 | loss 12.753 | train 85.76% | test 70.10%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 216/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e19d2d49a91b43a4ba6feb4278f0fb42"}},"metadata":{}},{"name":"stdout","text":"Epoch 216/240 | loss 12.753 | train 85.80% | test 70.11%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 217/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbcb12daee8f47e7bff938667859bbe7"}},"metadata":{}},{"name":"stdout","text":"Epoch 217/240 | loss 12.753 | train 85.70% | test 70.16%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 218/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a2e9ca381f64077a8f7cefedc39a138"}},"metadata":{}},{"name":"stdout","text":"Epoch 218/240 | loss 12.745 | train 85.87% | test 70.09%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 219/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e225b222c95c4628a8105c8b98def5a1"}},"metadata":{}},{"name":"stdout","text":"Epoch 219/240 | loss 12.753 | train 85.72% | test 70.22%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 220/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fea1637d0b724969a5dd0f1f9070d784"}},"metadata":{}},{"name":"stdout","text":"Epoch 220/240 | loss 12.751 | train 85.93% | test 70.33%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 221/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"315ea0cab108473ea9e78dc7ef0a6e8e"}},"metadata":{}},{"name":"stdout","text":"Epoch 221/240 | loss 12.747 | train 85.88% | test 70.03%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 222/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a16e63bbe2c4d88a8f261e2d03f5aa9"}},"metadata":{}},{"name":"stdout","text":"Epoch 222/240 | loss 12.754 | train 85.80% | test 70.11%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 223/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a55840381ecb47ec8842ed4bd3a9db0a"}},"metadata":{}},{"name":"stdout","text":"Epoch 223/240 | loss 12.747 | train 85.81% | test 70.11%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 224/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90a739c5670f46c78a370ea85ee82b03"}},"metadata":{}},{"name":"stdout","text":"Epoch 224/240 | loss 12.754 | train 85.80% | test 70.07%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 225/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ba48639fa174bc29c0fb3b4c7178c23"}},"metadata":{}},{"name":"stdout","text":"Epoch 225/240 | loss 12.746 | train 86.02% | test 70.12%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 226/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea300003d47b4313831f584ea09687bd"}},"metadata":{}},{"name":"stdout","text":"Epoch 226/240 | loss 12.749 | train 85.87% | test 70.09%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 227/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d508238b7a8419c831139c5a225ba8f"}},"metadata":{}},{"name":"stdout","text":"Epoch 227/240 | loss 12.752 | train 85.87% | test 70.03%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 228/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d70886ff1c034c538c349c9e7d6c0aad"}},"metadata":{}},{"name":"stdout","text":"Epoch 228/240 | loss 12.757 | train 85.74% | test 70.28%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 229/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b7fafb44238644969c1551f76ee62c3a"}},"metadata":{}},{"name":"stdout","text":"Epoch 229/240 | loss 12.757 | train 85.93% | test 70.21%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 230/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a922439335746debe3ddbf80c317d23"}},"metadata":{}},{"name":"stdout","text":"Epoch 230/240 | loss 12.752 | train 85.81% | test 70.08%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 231/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b67efda584474786908bff9af77d5646"}},"metadata":{}},{"name":"stdout","text":"Epoch 231/240 | loss 12.751 | train 85.69% | test 70.29%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 232/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9867e331b644f9095842c1a0e57e7b9"}},"metadata":{}},{"name":"stdout","text":"Epoch 232/240 | loss 12.749 | train 85.80% | test 70.21%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 233/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"343171b4817b4ec38f71dc4014f709cf"}},"metadata":{}},{"name":"stdout","text":"Epoch 233/240 | loss 12.756 | train 85.69% | test 70.26%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 234/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6af8e36a1a1b480a97acb1ad00b410ce"}},"metadata":{}},{"name":"stdout","text":"Epoch 234/240 | loss 12.762 | train 85.88% | test 69.96%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 235/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"14ac792c8f2a4ea7a0d5b1d968074013"}},"metadata":{}},{"name":"stdout","text":"Epoch 235/240 | loss 12.760 | train 85.83% | test 70.12%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 236/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7887cd8d81fc4149bbea59bd1e3683ed"}},"metadata":{}},{"name":"stdout","text":"Epoch 236/240 | loss 12.756 | train 86.07% | test 69.98%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 237/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f2d997e1db24c2d98962284070de57a"}},"metadata":{}},{"name":"stdout","text":"Epoch 237/240 | loss 12.754 | train 85.97% | test 70.01%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 238/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f54ead4bfde444aae77dfdead54cd58"}},"metadata":{}},{"name":"stdout","text":"Epoch 238/240 | loss 12.757 | train 85.98% | test 69.96%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 239/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbeba14136ad442e87d5256bc72fac07"}},"metadata":{}},{"name":"stdout","text":"Epoch 239/240 | loss 12.765 | train 85.81% | test 70.10%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[DiffKD] Epoch 240/240:   0%|          | 0/391 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9e02029b6f514caf8de134b65c5ab7eb"}},"metadata":{}},{"name":"stdout","text":"Epoch 240/240 | loss 12.756 | train 85.84% | test 70.17%\nâœ… DiffKD finished. Best Test Acc: 70.50%\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"70.5"},"metadata":{}}],"execution_count":8}]}