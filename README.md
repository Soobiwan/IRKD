# IRKD: Knowledge Distilled Vision Transformer with Inter-Resolution Training

This repository contains the implementation and experiments for IRKD (Inter-Resolution Knowledge Distillation), a novel approach to knowledge distillation for Vision Transformers.

## Project Structure

- `Experiment_1a.ipynb`: Initial experiments and implementation of IRKD
- `Experiment_1b.ipynb`: Follow-up experiments and refinements
- `Saliency_patch_size2.ipynb`: Experiments focusing on saliency analysis with different patch sizes

## Overview

IRKD is a knowledge distillation framework that leverages inter-resolution training to improve the performance of Vision Transformers. The approach combines knowledge distillation techniques with multi-resolution training strategies to enhance model efficiency and accuracy.

## Getting Started

1. Clone this repository
2. Install the required dependencies (to be added)
3. Open the Jupyter notebooks in the following order:
   - Start with `Experiment_1a.ipynb` for the basic implementation
   - Review `Experiment_1b.ipynb` for refined experiments
   - Explore `Saliency_patch_size2.ipynb` for detailed saliency analysis

## Key Features

- Inter-resolution training strategy
- Knowledge distillation implementation
- Saliency analysis with different patch sizes
- Comprehensive experimental results

## Requirements

(To be added based on the project's dependencies)

## Citation

If you use this code in your research, please cite:

(To be added)

## License

(To be added)

## Contact

(To be added)
